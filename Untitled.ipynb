{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-99546eebef30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fivethirtyeight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "# pd.options.display.max_rows = 20000\n",
    "# pd.options.display.max_columns = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# change campus names\n",
    "def change_campus(df):\n",
    "    \n",
    "    # school name dictionary\n",
    "    school_dict = {\n",
    "        'High': '',\n",
    "        'Elem School': '',\n",
    "        'Elementary': '',\n",
    "        'Middle': '',\n",
    "        'School': '',\n",
    "        'HS': '',\n",
    "        'ES': '',\n",
    "        'MS': '',\n",
    "        'Tr.': 'Trail',\n",
    "        '/Regular': '',\n",
    "        ' - ': ' ',\n",
    "        'Daep': 'DAEP',\n",
    "        'Juvenile Ctr': '',\n",
    "        'Wm.': '',\n",
    "        'Wm S': '',\n",
    "        'JJAEP/': '',\n",
    "        'Xenia': '',\n",
    "        'Liveoak': 'Live Oak',\n",
    "        'Linda Herrington': 'Herrington',\n",
    "        'Elsa ': '',\n",
    "        'Linda': 'Herrington',\n",
    "        'C. D. Fulkes': 'C.D. Fulkes',\n",
    "        'RROC': 'Round Rock Opportunity Center',\n",
    "        'RRISD ': '',\n",
    "        'Joe Lee ': '',\n",
    "        'James Walsh': 'Walsh',\n",
    "        'Neysa Callison': 'Callison',\n",
    "        'Kathy Caraway': 'Caraway',\n",
    "        'Noel Grisham': 'Grisham',\n",
    "        'Claude Berkman': 'Berkman',\n",
    "        'Patsy Sommer': 'Sommer',\n",
    "        '\\t\\r': '',\n",
    "        '  ': ' ',\n",
    "        'Lott': 'LOTT',\n",
    "        'Elem: DAEP': 'DAEP',\n",
    "        'Elem: ': '',\n",
    "    }\n",
    "    \n",
    "    # change keys(k) to values(v)\n",
    "    for k, v in school_dict.items():\n",
    "        df['Campus'] = df['Campus'].map(lambda dis_cell: dis_cell.replace(k, v).strip())\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_type = {\n",
    "    # list of middle schools\n",
    "    'C.D. Fulkes': 'MS',\n",
    "    'Canyon Vista': 'MS',\n",
    "    'Cedar Valley': 'MS',\n",
    "    'Chisholm Trail': 'MS',\n",
    "    'Deerpark': 'MS',\n",
    "    'Grisham': 'MS',\n",
    "    'Hernandez': 'MS',\n",
    "    'Hopewell': 'MS',\n",
    "    'Pearson Ranch': 'MS',\n",
    "    'Ridgeview': 'MS',\n",
    "    'Walsh': 'MS',\n",
    "    \n",
    "    # list of high schools\n",
    "    'Cedar Ridge': 'HS',\n",
    "    'McNeil': 'HS',\n",
    "    'Round Rock': 'HS',\n",
    "    'Stony Point': 'HS',\n",
    "    'Westwood': 'HS',\n",
    "    'Success': 'HS',\n",
    "    'Early College': 'HS',\n",
    "    \n",
    "    # other schools\n",
    "    'Round Rock Opportunity Center': 'Other',\n",
    "    'DAEP': 'Other',\n",
    "    'JJAEP': 'Other',\n",
    "    'LOTT': 'Other',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# path for excel files\n",
    "path = os.getcwd() + '/data/excel/'\n",
    "\n",
    "# read all pdf files in a directory and convert to pd dataframe\n",
    "# returns a dataframe\n",
    "def read_excel_files(path):\n",
    "    \n",
    "    # get all filesnames in a given folder\n",
    "    filenames = os.listdir(path)\n",
    "\n",
    "    # create an empty dataframe\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # count variable to count the number of files\n",
    "    count = 0\n",
    "    \n",
    "    # for each files in the given directory(path)\n",
    "    for filename in filenames:\n",
    "        \n",
    "        # print a filename\n",
    "        print(filename)\n",
    "        \n",
    "        # get each sheets in an excel file\n",
    "        sheets = pd.ExcelFile(path + filename).book.sheets()\n",
    "        \n",
    "        # for each sheets in a working excel file\n",
    "        for sheet in sheets:\n",
    "            \n",
    "            # check if there is a hidden sheet and its name isn't 'Enrollment Graphs'\n",
    "            if ((sheet.visibility == 0) & (sheet.name != 'Enrollment Graphs')):\n",
    "                \n",
    "                # read each sheet as a panda dataframe\n",
    "                temp = pd.read_excel(path + filename, header=2, sheet_name=sheet.name)\n",
    "                \n",
    "                # convert all column names into lowercase\n",
    "                temp.columns = [str(x).lower() for x in temp.columns]\n",
    "                \n",
    "                # columns of the dataframe from the sheet\n",
    "                cols = temp.columns\n",
    "                \n",
    "                # campus name which is the first column in the dataframe\n",
    "                campus_colname = cols[0]\n",
    "                \n",
    "                # cumulative column name\n",
    "                cum_colname = [col for col in [str(col).lower() for col in cols] if col.startswith('cum')][0]\n",
    "                \n",
    "                # projected column name\n",
    "                pro_colname= [col for col in [str(col).lower() for col in cols] if 'proj' in col][0]\n",
    "                \n",
    "                # select columns we want from the dataframe\n",
    "                temp = temp[[campus_colname, cum_colname, pro_colname]]\n",
    "                \n",
    "                # change column names\n",
    "                temp.columns = ['Campus', 'Cumulative', 'Projected']\n",
    "                \n",
    "                # get date from filenames and convert to datetime object\n",
    "                temp['Date'] = filename[:10]\n",
    "                \n",
    "                # change a filename with '.' instead of '-'\n",
    "                temp['Date'] = temp['Date'].str.replace(\".\", \"-\")\n",
    "                \n",
    "                # change Date column into datetime object\n",
    "                temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "\n",
    "                # remove unnecessary rows (total, campus - header rows)\n",
    "                temp = temp[temp['Campus'].str.contains('tota|campus', case=False, regex=True) != True]\n",
    "                \n",
    "                # append each temp dataframes(sheets) to df\n",
    "                df = df.append(temp, sort=False)\n",
    "        \n",
    "        # increment the number of files\n",
    "        count += 1\n",
    "    \n",
    "    # print how many files are converted\n",
    "    print('number of files:', count)\n",
    "    \n",
    "    # change ' ' to integer 0 in 'Projected' column\n",
    "    df['Projected'].loc[df['Projected'] == ' '] = 0\n",
    "\n",
    "    # drop NaNs\n",
    "    df = df.dropna()\n",
    "\n",
    "    # change each columns data types\n",
    "    df['Cumulative'] = df['Cumulative'].astype(int)\n",
    "    df['Projected'] = df['Projected'].astype(int)\n",
    "\n",
    "    # create 'Difference' column\n",
    "    df['Difference'] = df['Cumulative'] - df['Projected']\n",
    "    \n",
    "    # change school names\n",
    "    change_campus(df)\n",
    "    \n",
    "    # sort and reset index\n",
    "    df.sort_values(by=['Date', 'Campus'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a variable\n",
    "excel_df = read_excel_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/data/pdf/'\n",
    "\n",
    "def read_pdf_files(path):\n",
    "    filenames = os.listdir(path)\n",
    "    pdf_df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('pdf'):\n",
    "            print(filename)\n",
    "            try :\n",
    "                # read all pages from a pdf\n",
    "                # pdf returns a list of dataframes\n",
    "                # one dataframe for each page (pdf[0], pdf[1]...)\n",
    "                # does not merge files don't have projected numbers\n",
    "                pdf = tabula.read_pdf(path + filename, pages='all', multiple_tables=True, spreadsheet=True)\n",
    "\n",
    "                # merge all dataframes into one    \n",
    "                pdf = pd.concat(pdf, join='inner', axis=0)\n",
    "\n",
    "                # get columns we want, rename columns\n",
    "                pdf = pdf[[0, 17, 18]]\n",
    "                pdf = pdf.rename({0: 'Campus', 17: 'Cumulative', 18: 'Projected'}, axis='columns')\n",
    "\n",
    "                # remove unnecessary rows (total, campus - header rows)\n",
    "                pdf = pdf[pdf['Campus'].str.contains('tot|campus', case=False, regex=True) != True]\n",
    "\n",
    "                # remove rows that cumulative is NaN (like Anderson Mill Non‐LEP DL, Anderson Mill/ESOL)\n",
    "                pdf = pdf[pdf['Cumulative'].notna()]\n",
    "\n",
    "                # get dates from a filename\n",
    "                filename = filename.replace('.pdf', '').strip()\n",
    "                filename = filename.replace(' -  last day of school', '').strip()\n",
    "                if len(filename) == 10:\n",
    "                    filename = datetime.datetime.strptime(filename, '%m-%d-%Y')\n",
    "                elif len(filename) == 8:\n",
    "                    filename = datetime.datetime.strptime(filename, '%m-%d-%y')\n",
    "                pdf['Date'] = filename\n",
    "\n",
    "\n",
    "                pdf_df = pdf_df.append(pdf)\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            except KeyError:\n",
    "                print(filename, 'Did not merge')\n",
    "\n",
    "    pdf_df.sort_values(by=['Date', 'Campus'], inplace=True)\n",
    "    pdf_df.reset_index(drop=True, inplace=True)\n",
    "    print('number of files:', count)\n",
    "\n",
    "    print('changing datatypes')\n",
    "    pdf_df['Cumulative'] = pdf_df['Cumulative'].astype(int)\n",
    "    pdf_df['Projected'] = pdf_df['Projected'].astype(int)\n",
    "    pdf_df['Difference'] = pdf_df['Cumulative'] - pdf_df['Projected']\n",
    "    \n",
    "    change_campus(pdf_df)\n",
    "    \n",
    "    return pdf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_df = read_pdf_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Target'] = combined.groupby(\"Campus\")['Cumulative'].shift(-1)\n",
    "combined = combined.dropna()\n",
    "count = 0\n",
    "for i in set(combined['Campus'].value_counts().index):\n",
    "    count += 1\n",
    "    df_school = combined[combined['Campus'] == i]\n",
    "    df_school = df_school.dropna()\n",
    "    X = df_school[['Cumulative']]\n",
    "    y = df_school[['Campus', 'Cumulative', 'Projected', 'Date', 'Difference', 'Target']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train['Target'])\n",
    "    predictions = lr.predict(X_test)\n",
    "    y_test['Predicted'] = predictions\n",
    "#     plt.figure(figsize=(20,5))\n",
    "#     plt.title(i)\n",
    "#     plt.scatter(x=df_school['Date'], y=df_school['Projected']);\n",
    "#     plt.scatter(x=df_school['Date'], y=df_school['Cumulative']);\n",
    "#     plt.scatter(x=df_school['Date'], y=df_school['Predicted']);\n",
    "    print(i, count)\n",
    "    print(lr.score(X_test, y_test['Target']))\n",
    "    print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_datetime = combined\n",
    "df_datetime['Date'] = pd.to_datetime(df_datetime['Date'])\n",
    "df_datetime = df_datetime.set_index('Date')\n",
    "\n",
    "for i in set(df_datetime['Campus'].value_counts().index):\n",
    "    try:\n",
    "    #        df_school = df[df['Campus'] == i]\n",
    "        df_train_school = df_datetime['20120810':'20160610']\n",
    "        df_test_school = df_datetime['20160701':'20181016']\n",
    "        df_train_school = df_train_school[df_train_school['Campus'] == i]\n",
    "        df_test_school = df_test_school[df_test_school['Campus'] == i]\n",
    "        X_train = df_train_school[['Cumulative']]\n",
    "        y_train = df_train_school['Target']\n",
    "        X_test = df_test_school[['Cumulative']]\n",
    "        y_test = df_test_school['Target']\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        predictions = lr.predict(X_test)\n",
    "        df_test_school['Predicted'] = predictions\n",
    "        df_test_school['Pred Diff'] = df_test_school['Predicted'] - df_test_school['Cumulative']\n",
    "\n",
    "    #    print(df_test_school['Pred Diff'].sum())\n",
    "    #         y_test['Predicted'] = predictions\n",
    "    #         plt.figure(figsize=(20,5))\n",
    "    #         plt.title(i)\n",
    "    #         plt.scatter(x=df_school['Date'], y=df_school['Projected']);\n",
    "    #         plt.scatter(x=df_school['Date'], y=df_school['Cumulative']);\n",
    "    #         plt.scatter(x=y_test['Date'], y=y_test['Predicted']);\n",
    "        print(i)\n",
    "        print('RMSE Our Prediction: ' + str(math.sqrt(mean_squared_error(y_test, predictions))))\n",
    "        print('RMSE RRISD Prediction: ' + str(math.sqrt(mean_squared_error(df_test_school['Cumulative'], df_test_school['Projected']))))\n",
    "        print(lr.score(X_test, y_test))\n",
    "        print('-----------------------------------------------------')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# path for excel files\n",
    "path = os.getcwd() + '/data/'\n",
    "\n",
    "# read all pdf files in a directory and convert to pd dataframe\n",
    "# returns a dataframe\n",
    "def read_files(path):\n",
    "    \n",
    "    # get all filesnames in a given folder\n",
    "    filenames = os.listdir(path)\n",
    "    print(len(filenames), 'files total')\n",
    "    \n",
    "    # create empty dataframes\n",
    "    df_excel = pd.DataFrame()\n",
    "    df_pdf = pd.DataFrame()\n",
    "    \n",
    "    # count variable to count the number of files\n",
    "    count_excel = 0\n",
    "    count_pdf = 0\n",
    "    \n",
    "    # for each files in the given directory(path)\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        \n",
    "        # if filename ends with 'xlsx'\n",
    "        if filename.endswith('xlsx'):\n",
    "\n",
    "            # get each sheets in an excel file\n",
    "            sheets = pd.ExcelFile(path + filename).book.sheets()\n",
    "\n",
    "            # for each sheets in a working excel file\n",
    "            for sheet in sheets:\n",
    "\n",
    "                # check if there is a hidden sheet and its name isn't 'Enrollment Graphs'\n",
    "                if ((sheet.visibility == 0) & (sheet.name != 'Enrollment Graphs')):\n",
    "\n",
    "                    # read each sheet as a panda dataframe\n",
    "                    temp = pd.read_excel(path + filename, header=2, sheet_name=sheet.name)\n",
    "\n",
    "                    # convert all column names into lowercase\n",
    "                    temp.columns = [str(x).lower() for x in temp.columns]\n",
    "\n",
    "                    # columns of the dataframe from the sheet\n",
    "                    cols = temp.columns\n",
    "\n",
    "                    # campus name which is the first column in the dataframe\n",
    "                    campus_colname = cols[0]\n",
    "\n",
    "                    # cumulative column name\n",
    "                    cum_colname = [col for col in [str(col).lower() for col in cols] if col.startswith('cum')][0]\n",
    "\n",
    "                    # projected column name\n",
    "                    pro_colname= [col for col in [str(col).lower() for col in cols] if 'proj' in col][0]\n",
    "\n",
    "                    # select columns we want from the dataframe\n",
    "                    temp = temp[[campus_colname, cum_colname, pro_colname]]\n",
    "\n",
    "                    # change column names\n",
    "                    temp.columns = ['Campus', 'Cumulative', 'Projected']\n",
    "\n",
    "                    # get date from filenames and convert to datetime object\n",
    "                    temp['Date'] = filename[:10]\n",
    "\n",
    "                    # change a filename with '.' instead of '-'\n",
    "                    temp['Date'] = temp['Date'].str.replace(\".\", \"-\")\n",
    "\n",
    "                    # change Date column into datetime object\n",
    "                    temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "\n",
    "                    # remove unnecessary rows (total, campus - header rows)\n",
    "                    temp = temp[temp['Campus'].str.contains('tota|campus', case=False, regex=True) != True]\n",
    "\n",
    "                    # append each temp dataframes(sheets) to df\n",
    "                    df_excel = df_excel.append(temp, sort=False)\n",
    "\n",
    "            # increment the number of files\n",
    "            count_excel += 1\n",
    "        \n",
    "        elif filename.endswith('pdf'):\n",
    "            try :\n",
    "                # read all pages from a pdf\n",
    "                # pdf returns a list of dataframes\n",
    "                # one dataframe for each page (pdf[0], pdf[1]...)\n",
    "                # does not merge files don't have projected numbers\n",
    "                pdf = tabula.read_pdf(path + filename, pages='all', multiple_tables=True, spreadsheet=True)\n",
    "\n",
    "                # merge all dataframes into one    \n",
    "                pdf = pd.concat(pdf, join='inner', axis=0)\n",
    "\n",
    "                # get columns we want, rename columns\n",
    "                pdf = pdf[[0, 17, 18]]\n",
    "                pdf = pdf.rename({0: 'Campus', 17: 'Cumulative', 18: 'Projected'}, axis='columns')\n",
    "\n",
    "                # remove unnecessary rows (total, campus - header rows)\n",
    "                pdf = pdf[pdf['Campus'].str.contains('tot|campus', case=False, regex=True) != True]\n",
    "\n",
    "                # remove rows that cumulative is NaN (like Anderson Mill Non‐LEP DL, Anderson Mill/ESOL)\n",
    "                pdf = pdf[pdf['Cumulative'].notna()]\n",
    "\n",
    "                # get dates from a filename\n",
    "                filename = filename.replace('.pdf', '').strip()\n",
    "                filename = filename.replace(' -  last day of school', '').strip()\n",
    "                if len(filename) == 10:\n",
    "                    filename = datetime.datetime.strptime(filename, '%m-%d-%Y')\n",
    "                elif len(filename) == 8:\n",
    "                    filename = datetime.datetime.strptime(filename, '%m-%d-%y')\n",
    "                pdf['Date'] = filename\n",
    "\n",
    "\n",
    "                df_pdf = df_pdf.append(pdf)\n",
    "\n",
    "                count_pdf += 1\n",
    "\n",
    "            except KeyError:\n",
    "                print(filename, 'Did not merge')\n",
    "\n",
    "    # print how many files are converted\n",
    "    print('number of excel files:', count_excel)\n",
    "    print('number of pdf files:', count_pdf)\n",
    "\n",
    "    # change ' ' to integer 0 in 'Projected' column\n",
    "    df_excel['Projected'].loc[df_excel['Projected'] == ' '] = 0\n",
    "    \n",
    "    # drop NaNs in excel dataframe\n",
    "    df_excel = df_excel.dropna()\n",
    "    \n",
    "    # change each columns data types\n",
    "    print('changing datatypes')\n",
    "    df_excel['Cumulative'] = df_excel['Cumulative'].astype(int)\n",
    "    df_excel['Projected'] = df_excel['Projected'].astype(int)\n",
    "    df_pdf['Cumulative'] = df_pdf['Cumulative'].astype(int)\n",
    "    df_pdf['Projected'] = df_pdf['Projected'].astype(int)\n",
    "    df_pdf['Difference'] = df_pdf['Cumulative'] - df_pdf['Projected']    \n",
    "\n",
    "    # create 'Difference' column\n",
    "    df_excel['Difference'] = df_excel['Cumulative'] - df_excel['Projected']\n",
    "    \n",
    "    # merge two dataframes\n",
    "    print('merging dataframes')\n",
    "    combined = pd.concat([df_pdf, df_excel], join='outer', axis=0, sort=False)\n",
    "    combined.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # sort and reset index\n",
    "    combined.sort_values(by=['Date', 'Campus'], inplace=True)\n",
    "    combined.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # changing school names\n",
    "    print('school name change')\n",
    "    change_campus(combined)\n",
    "\n",
    "    print('changing school types')\n",
    "    for i in range(len(combined)):\n",
    "        if combined.loc[i, 'Campus'] in school_type.keys():\n",
    "            combined.loc[i, 'Type'] = school_type[combined.loc[i, 'Campus']]\n",
    "        else:\n",
    "            combined.loc[i, 'Type'] = 'ES'\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 files total\n",
      "11-04-14.pdf\n",
      "01-08-13.pdf.pdf\n",
      "2017-04-11 enrollment.xls.xlsx\n",
      "03-25-2014.pdf\n",
      "12-11-12.pdf.pdf\n",
      "2017-02-07 enrollment.xls.xlsx\n",
      "02-18-2014.pdf\n",
      "09-22-2015.pdf\n",
      "04-08-2014.pdf\n",
      "09-02-14.pdf\n",
      "09-23-2014.pdf\n",
      "03-24-2015.pdf\n",
      "2018-04-17 enrollment.xls.xlsx\n",
      "11-03-2015.pdf\n",
      "02-26-13.pdf.pdf\n",
      "01-14-2014.pdf\n",
      "2017-09-12 enrollment.xls.xlsx\n",
      "01-21-2014.pdf\n",
      "04-29-2014 .pdf\n",
      "09-29-2015.pdf\n",
      "03-10-2015.pdf\n",
      "2016-10-04 enrollment.xls.xlsx\n",
      "09-16-2014.pdf\n",
      "2016-09-20 enrollment.xls.xlsx\n",
      "2018-05-01 enrollment.xls.xlsx\n",
      "2016-11-08 enrollment.xls.xlsx\n",
      "01-20-2015.pdf\n",
      "2018-09-04 Enrollment Report.xls.xlsx\n",
      ".DS_Store\n",
      "10-28-14.pdf\n",
      "04-21-2015.pdf\n",
      "2016-09-27 enrollment.xls.xlsx\n",
      "05-17-2016.pdf\n",
      "02-19-13.pdf.pdf\n",
      "2017-10-31 enrollment.xls.xlsx\n",
      "2017-05-02 enrollment.xls.xlsx\n",
      "11-18-14.pdf\n",
      "2016-10-18 enrollment.xls.xlsx\n",
      "2016-11-15 enrollment.xls.xlsx\n",
      "04-14-2015.pdf\n",
      "2016-12-13 enrollment.xls.xlsx\n",
      "2018-04-10 enrollment.xls.xlsx\n",
      "2018-02-06 enrollment.xls.xlsx\n",
      "09-01-2015.pdf\n",
      "03-01-2016.pdf\n",
      "04-09-13.pdf.pdf\n",
      "10-08-14.pdf\n",
      "2017-10-24 enrollment.xls.xlsx\n",
      "08-26-14.pdf\n",
      "04-12-2016.pdf\n",
      "2018-03-06 enrollment.xls.xlsx\n",
      "2017-11-28 enrollment.xls.xlsx\n",
      "2017-05-16 enrollment.xls.xlsx\n",
      "2017-09-19 enrollment.xls.xlsx\n",
      "2016-12-06 enrollment.xls.xlsx\n",
      "02-02-2016.pdf\n",
      "2018-05-08 enrollment.xls.xlsx\n",
      "05-10-2016.pdf\n",
      "2016-11-01 enrollment.xls.xlsx\n",
      "2017-02-14 enrollment.xls.xlsx\n",
      "05-24-2016.pdf\n",
      "12-09-14.pdf\n",
      "04-19-2016.pdf\n",
      "2017-04-18 enrollment.xls.xlsx\n",
      "2017-01-10 enrollment.xls.xlsx\n",
      "01-05-2016.pdf\n",
      "12-15-2015.pdf\n",
      "2018-01-16 enrollment.xls.xlsx\n",
      "02-03-2015.pdf\n",
      "04-26-2016.pdf\n",
      "02-09-2016.pdf\n",
      "2018-10-02 Enrollment Report.xls.xlsx\n",
      "02-04-2014 .pdf\n",
      "2018-05-15 enrollment.xls.xlsx\n",
      "01-29-13.pdf.pdf\n",
      "01-13-2015.pdf\n",
      "2018-10-09 Enrollment Report.xls.xlsx\n",
      "01-19-2016.pdf\n",
      "10-06-2015.pdf\n",
      "2017-01-17 enrollment.xls.xlsx\n",
      "2016-10-11 enrollment.xls.xlsx\n",
      "2018-01-09 enrollment.xls.xlsx\n",
      "12-08-2015.pdf\n",
      "2017-09-05 enrollment.xls.xlsx\n",
      "06-02-2016 -  last day of school.pdf\n",
      "01-26-2016.pdf\n",
      "03-29-2016.pdf\n",
      "2018-04-03 enrollment.xls.xlsx\n",
      "2018-09-18 Enrollment Report.xls.xlsx\n",
      "01-12-2016.pdf\n",
      "2017-05-09 enrollment.xls.xlsx\n",
      "2017-04-04 enrollment.xls.xlsx\n",
      "05-06-2014.pdf\n",
      "2017-03-07 enrollment.xls.xlsx\n",
      "03-22-2016.pdf\n",
      "2016-08-23 enrollment.xls.xlsx\n",
      "10-22-14.pdf\n",
      "01-27-2015.pdf\n",
      "11-13-12.pdf.pdf\n",
      "2017-01-24 enrollment.xls.xlsx\n",
      "12-18-12.pdf.pdf\n",
      "2018-01-23 enrollment.xls.xlsx\n",
      "2018-09-11 Enrollment Report.xls.xlsx\n",
      "12-04-12.pdf.pdf\n",
      "2017-12-19 enrollment.xls.xlsx\n",
      "2016-09-06 enrollment.xls.xlsx\n",
      "03-04-2014.pdf\n",
      "2017-11-07 enrollment.xls.xlsx\n",
      "2016-08.30 enrollment.xls.xlsx\n",
      "04-28-2015.pdf\n",
      "10-02-12.pdf.pdf\n",
      "10-20-2015.pdf\n",
      "2017-02-21 enrollment.xls.xlsx\n",
      "11-27-12.pdf.pdf\n",
      "04-22-2014.pdf\n",
      "2017-05-23 enrollment.xls.xlsx\n",
      "09-09-2014.pdf\n",
      "12-02-14.pdf\n",
      "2017-10-10 enrollment.xls.xlsx\n",
      "09-08-2015.pdf\n",
      "2018-10-23 Enrollment Report.xls.xlsx\n",
      "11-17-2015.pdf\n",
      "05-20-2014.pdf\n",
      "03-31-2015.pdf\n",
      "2018-10-16 Enrollment Report.xls.xlsx\n",
      "2018-02-27 enrollment.xls.xlsx\n",
      "02-11-2014.pdf\n",
      "02-11-2014.pdf Did not merge\n",
      "10-16-12.pdf.pdf\n",
      "2018-03-27 enrollments.xls.xlsx\n",
      "2017-10-17 enrollment.xls.xlsx\n",
      "2018-05-22 enrollment.xls.xlsx\n",
      "09-15-2015.pdf\n",
      "04-15-2014 .pdf\n",
      "09-11-12.pdf.pdf\n",
      "2017-12-05 enrollment.xls.xlsx\n",
      "01-15-13.pdf.pdf\n",
      "04-01-2014.pdf\n",
      "2018-02-20 enrollment.xls.xlsx\n",
      "01-22-13.pdf.pdf\n",
      "02-10-2015.pdf\n",
      "02-24-2015.pdf\n",
      "02-24-2015.pdf Did not merge\n",
      "2016-10-25 enrollment.xls.xlsx\n",
      "10-30-12.pdf.pdf\n",
      "2016-11-29 enrollment.xls.xlsx\n",
      "05-03-2016.pdf\n",
      "2017-03-28 enrollment.xls.xlsx\n",
      "03-18-2014.pdf\n",
      "02-25-2014.pdf\n",
      "2017-02-28 enrollment.xls.xlsx\n",
      "12-01-2015.pdf\n",
      "02-23-2016.pdf\n",
      "04-07-2015.pdf\n",
      "2017-08-22 first day of school.xls.xlsx\n",
      "11-11-14.pdf\n",
      "2017-11-14 enrollment.xls.xlsx\n",
      "12-16-14.pdf\n",
      "05-05-2015.pdf\n",
      "2017-12-12 enrollment.xls.xlsx\n",
      "2017-08-29 enrollment.xls.xlsx\n",
      "2018-01-30 enrollment.xls.xlsx\n",
      "2017-04-25 enrollment.xls.xlsx\n",
      "2018-03-20 enrollment.xls.xlsx\n",
      "04-06-2016.pdf\n",
      "06-02-2015.pdf\n",
      "06-02-2015.pdf Did not merge\n",
      "2017-09-26 enrollment.xls.xlsx\n",
      "2017-05-30 enrollment.xls.xlsx\n",
      "2017-10-03 enrollment.xls.xlsx\n",
      "02-16-2016.pdf\n",
      "08-25-2015.pdf\n",
      "2018-08-28 Enrollment Report.xls.xlsx\n",
      "05-13-2014.pdf\n",
      "02-12-13.pdf.pdf\n",
      "03-03-2015.pdf\n",
      "2018-09-25 Enrollment Report.xls.xlsx\n",
      "03-08-2016.pdf\n",
      "10-15-14.pdf\n",
      "10-23-12.pdf.pdf\n",
      "10-27-2015.pdf\n",
      "2017-03-21 enrollment.xls.xlsx\n",
      "2018-04-24 enrollment.xls.xlsx\n",
      "2018-05-29 enrollment.xls.xlsx\n",
      "05-12-2015.pdf\n",
      "04-23-13.pdf.pdf\n",
      "11-06-12.pdf.pdf\n",
      "05-26-2015.pdf\n",
      "2017-01-31 enrollment.xls.xlsx\n",
      "10-13-2015.pdf\n",
      "01-06-2015.pdf\n",
      "01-29-2014 .pdf\n",
      "02-17-15.pdf\n",
      "05-19-2015.pdf\n",
      "11-10-2015.pdf\n",
      "01-07-2014.pdf\n",
      "09-30-2014.pdf\n",
      "2016-09-13 enrollment.xls.xlsx\n",
      "05-27-2014.pdf\n",
      "11-25-14.pdf\n",
      "number of excel files: 81\n",
      "number of pdf files: 112\n",
      "changing datatypes\n",
      "merging dataframes\n",
      "school name change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing school types\n"
     ]
    }
   ],
   "source": [
    "combined = read_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Campus</th>\n",
       "      <th>Cumulative</th>\n",
       "      <th>Projected</th>\n",
       "      <th>Date</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anderson Mill</td>\n",
       "      <td>465</td>\n",
       "      <td>545</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-80</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berkman</td>\n",
       "      <td>526</td>\n",
       "      <td>551</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-25</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blackland Prairie</td>\n",
       "      <td>903</td>\n",
       "      <td>895</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>8</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bluebonnet</td>\n",
       "      <td>634</td>\n",
       "      <td>713</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-79</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brushy Creek</td>\n",
       "      <td>778</td>\n",
       "      <td>782</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-4</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C.D. Fulkes</td>\n",
       "      <td>791</td>\n",
       "      <td>741</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>50</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cactus Ranch</td>\n",
       "      <td>984</td>\n",
       "      <td>951</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>33</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Caldwell Heights</td>\n",
       "      <td>598</td>\n",
       "      <td>646</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-48</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Callison</td>\n",
       "      <td>863</td>\n",
       "      <td>930</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-67</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Canyon Creek</td>\n",
       "      <td>437</td>\n",
       "      <td>464</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-27</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Canyon Vista</td>\n",
       "      <td>1273</td>\n",
       "      <td>1259</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>14</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Caraway</td>\n",
       "      <td>659</td>\n",
       "      <td>689</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-30</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cedar Ridge</td>\n",
       "      <td>2879</td>\n",
       "      <td>2979</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-100</td>\n",
       "      <td>HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cedar Valley</td>\n",
       "      <td>1250</td>\n",
       "      <td>1241</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>9</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chandler Oaks</td>\n",
       "      <td>617</td>\n",
       "      <td>618</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-1</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chisholm Trail</td>\n",
       "      <td>1061</td>\n",
       "      <td>1073</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-12</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Deepwood</td>\n",
       "      <td>409</td>\n",
       "      <td>411</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-2</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Deerpark</td>\n",
       "      <td>950</td>\n",
       "      <td>990</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-40</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Double File Trail</td>\n",
       "      <td>681</td>\n",
       "      <td>706</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-25</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DAEP</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-4</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>England</td>\n",
       "      <td>513</td>\n",
       "      <td>516</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-3</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Fern Bluff</td>\n",
       "      <td>761</td>\n",
       "      <td>782</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-21</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Forest Creek</td>\n",
       "      <td>824</td>\n",
       "      <td>827</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-3</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Forest North</td>\n",
       "      <td>380</td>\n",
       "      <td>399</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-19</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gattis</td>\n",
       "      <td>785</td>\n",
       "      <td>779</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>6</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Great Oaks</td>\n",
       "      <td>753</td>\n",
       "      <td>819</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-66</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Grisham</td>\n",
       "      <td>685</td>\n",
       "      <td>671</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>14</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hernandez</td>\n",
       "      <td>865</td>\n",
       "      <td>936</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>-71</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Herrington</td>\n",
       "      <td>702</td>\n",
       "      <td>644</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>58</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Hopewell</td>\n",
       "      <td>870</td>\n",
       "      <td>854</td>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>16</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10255</th>\n",
       "      <td>JJAEP</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>6</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10256</th>\n",
       "      <td>Walsh</td>\n",
       "      <td>1347</td>\n",
       "      <td>1389</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-42</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10257</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>804</td>\n",
       "      <td>807</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-3</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10258</th>\n",
       "      <td>Jollyville</td>\n",
       "      <td>453</td>\n",
       "      <td>440</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>13</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10259</th>\n",
       "      <td>Caraway</td>\n",
       "      <td>876</td>\n",
       "      <td>814</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>62</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10260</th>\n",
       "      <td>Laurel Mountain</td>\n",
       "      <td>731</td>\n",
       "      <td>732</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-1</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10261</th>\n",
       "      <td>Herrington</td>\n",
       "      <td>1116</td>\n",
       "      <td>1116</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10262</th>\n",
       "      <td>Live Oak</td>\n",
       "      <td>598</td>\n",
       "      <td>571</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>27</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10263</th>\n",
       "      <td>McNeil</td>\n",
       "      <td>2677</td>\n",
       "      <td>2758</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-81</td>\n",
       "      <td>HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>Callison</td>\n",
       "      <td>785</td>\n",
       "      <td>810</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-25</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>Grisham</td>\n",
       "      <td>641</td>\n",
       "      <td>621</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>20</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>Old Town</td>\n",
       "      <td>716</td>\n",
       "      <td>715</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>1</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>Sommer</td>\n",
       "      <td>1257</td>\n",
       "      <td>1289</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-32</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>Pearson Ranch</td>\n",
       "      <td>881</td>\n",
       "      <td>820</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>61</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10269</th>\n",
       "      <td>Pond Springs</td>\n",
       "      <td>593</td>\n",
       "      <td>626</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-33</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10270</th>\n",
       "      <td>Purple Sage</td>\n",
       "      <td>489</td>\n",
       "      <td>471</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>18</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10271</th>\n",
       "      <td>Early College</td>\n",
       "      <td>288</td>\n",
       "      <td>331</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-43</td>\n",
       "      <td>HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10272</th>\n",
       "      <td>Ridgeview</td>\n",
       "      <td>1367</td>\n",
       "      <td>1333</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>34</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10273</th>\n",
       "      <td>Robertson</td>\n",
       "      <td>438</td>\n",
       "      <td>414</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>24</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10274</th>\n",
       "      <td>Round Rock</td>\n",
       "      <td>3504</td>\n",
       "      <td>3515</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-11</td>\n",
       "      <td>HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10275</th>\n",
       "      <td>Round Rock Opportunity Center</td>\n",
       "      <td>62</td>\n",
       "      <td>79</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-17</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10276</th>\n",
       "      <td>Spicewood</td>\n",
       "      <td>846</td>\n",
       "      <td>812</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>34</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10277</th>\n",
       "      <td>Stony Point</td>\n",
       "      <td>2600</td>\n",
       "      <td>2635</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-35</td>\n",
       "      <td>HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10278</th>\n",
       "      <td>Success</td>\n",
       "      <td>323</td>\n",
       "      <td>315</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>8</td>\n",
       "      <td>HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10279</th>\n",
       "      <td>Teravista</td>\n",
       "      <td>878</td>\n",
       "      <td>841</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>37</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10280</th>\n",
       "      <td>Union Hill</td>\n",
       "      <td>774</td>\n",
       "      <td>723</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>51</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10281</th>\n",
       "      <td>Wells Branch</td>\n",
       "      <td>481</td>\n",
       "      <td>486</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-5</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10282</th>\n",
       "      <td>Westwood</td>\n",
       "      <td>2760</td>\n",
       "      <td>2770</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>-10</td>\n",
       "      <td>HS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10283</th>\n",
       "      <td>LOTT</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10284</th>\n",
       "      <td>Voigt</td>\n",
       "      <td>586</td>\n",
       "      <td>498</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>88</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10285 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Campus  Cumulative  Projected       Date  \\\n",
       "0                      Anderson Mill         465        545 2012-09-11   \n",
       "1                            Berkman         526        551 2012-09-11   \n",
       "2                  Blackland Prairie         903        895 2012-09-11   \n",
       "3                         Bluebonnet         634        713 2012-09-11   \n",
       "4                       Brushy Creek         778        782 2012-09-11   \n",
       "5                        C.D. Fulkes         791        741 2012-09-11   \n",
       "6                       Cactus Ranch         984        951 2012-09-11   \n",
       "7                   Caldwell Heights         598        646 2012-09-11   \n",
       "8                           Callison         863        930 2012-09-11   \n",
       "9                       Canyon Creek         437        464 2012-09-11   \n",
       "10                      Canyon Vista        1273       1259 2012-09-11   \n",
       "11                           Caraway         659        689 2012-09-11   \n",
       "12                       Cedar Ridge        2879       2979 2012-09-11   \n",
       "13                      Cedar Valley        1250       1241 2012-09-11   \n",
       "14                     Chandler Oaks         617        618 2012-09-11   \n",
       "15                    Chisholm Trail        1061       1073 2012-09-11   \n",
       "16                          Deepwood         409        411 2012-09-11   \n",
       "17                          Deerpark         950        990 2012-09-11   \n",
       "18                 Double File Trail         681        706 2012-09-11   \n",
       "19                              DAEP           2          6 2012-09-11   \n",
       "20                           England         513        516 2012-09-11   \n",
       "21                        Fern Bluff         761        782 2012-09-11   \n",
       "22                      Forest Creek         824        827 2012-09-11   \n",
       "23                      Forest North         380        399 2012-09-11   \n",
       "24                            Gattis         785        779 2012-09-11   \n",
       "25                        Great Oaks         753        819 2012-09-11   \n",
       "26                           Grisham         685        671 2012-09-11   \n",
       "27                         Hernandez         865        936 2012-09-11   \n",
       "28                        Herrington         702        644 2012-09-11   \n",
       "29                          Hopewell         870        854 2012-09-11   \n",
       "...                              ...         ...        ...        ...   \n",
       "10255                          JJAEP          12          6 2018-10-23   \n",
       "10256                          Walsh        1347       1389 2018-10-23   \n",
       "10257                        Johnson         804        807 2018-10-23   \n",
       "10258                     Jollyville         453        440 2018-10-23   \n",
       "10259                        Caraway         876        814 2018-10-23   \n",
       "10260                Laurel Mountain         731        732 2018-10-23   \n",
       "10261                     Herrington        1116       1116 2018-10-23   \n",
       "10262                       Live Oak         598        571 2018-10-23   \n",
       "10263                         McNeil        2677       2758 2018-10-23   \n",
       "10264                       Callison         785        810 2018-10-23   \n",
       "10265                        Grisham         641        621 2018-10-23   \n",
       "10266                       Old Town         716        715 2018-10-23   \n",
       "10267                         Sommer        1257       1289 2018-10-23   \n",
       "10268                  Pearson Ranch         881        820 2018-10-23   \n",
       "10269                   Pond Springs         593        626 2018-10-23   \n",
       "10270                    Purple Sage         489        471 2018-10-23   \n",
       "10271                  Early College         288        331 2018-10-23   \n",
       "10272                      Ridgeview        1367       1333 2018-10-23   \n",
       "10273                      Robertson         438        414 2018-10-23   \n",
       "10274                     Round Rock        3504       3515 2018-10-23   \n",
       "10275  Round Rock Opportunity Center          62         79 2018-10-23   \n",
       "10276                      Spicewood         846        812 2018-10-23   \n",
       "10277                    Stony Point        2600       2635 2018-10-23   \n",
       "10278                        Success         323        315 2018-10-23   \n",
       "10279                      Teravista         878        841 2018-10-23   \n",
       "10280                     Union Hill         774        723 2018-10-23   \n",
       "10281                   Wells Branch         481        486 2018-10-23   \n",
       "10282                       Westwood        2760       2770 2018-10-23   \n",
       "10283                           LOTT           6          3 2018-10-23   \n",
       "10284                          Voigt         586        498 2018-10-23   \n",
       "\n",
       "       Difference   Type  \n",
       "0             -80     ES  \n",
       "1             -25     ES  \n",
       "2               8     ES  \n",
       "3             -79     ES  \n",
       "4              -4     ES  \n",
       "5              50     MS  \n",
       "6              33     ES  \n",
       "7             -48     ES  \n",
       "8             -67     ES  \n",
       "9             -27     ES  \n",
       "10             14     MS  \n",
       "11            -30     ES  \n",
       "12           -100     HS  \n",
       "13              9     MS  \n",
       "14             -1     ES  \n",
       "15            -12     MS  \n",
       "16             -2     ES  \n",
       "17            -40     MS  \n",
       "18            -25     ES  \n",
       "19             -4  Other  \n",
       "20             -3     ES  \n",
       "21            -21     ES  \n",
       "22             -3     ES  \n",
       "23            -19     ES  \n",
       "24              6     ES  \n",
       "25            -66     ES  \n",
       "26             14     MS  \n",
       "27            -71     MS  \n",
       "28             58     ES  \n",
       "29             16     MS  \n",
       "...           ...    ...  \n",
       "10255           6  Other  \n",
       "10256         -42     MS  \n",
       "10257          -3     ES  \n",
       "10258          13     ES  \n",
       "10259          62     ES  \n",
       "10260          -1     ES  \n",
       "10261           0     ES  \n",
       "10262          27     ES  \n",
       "10263         -81     HS  \n",
       "10264         -25     ES  \n",
       "10265          20     MS  \n",
       "10266           1     ES  \n",
       "10267         -32     ES  \n",
       "10268          61     MS  \n",
       "10269         -33     ES  \n",
       "10270          18     ES  \n",
       "10271         -43     HS  \n",
       "10272          34     MS  \n",
       "10273          24     ES  \n",
       "10274         -11     HS  \n",
       "10275         -17  Other  \n",
       "10276          34     ES  \n",
       "10277         -35     HS  \n",
       "10278           8     HS  \n",
       "10279          37     ES  \n",
       "10280          51     ES  \n",
       "10281          -5     ES  \n",
       "10282         -10     HS  \n",
       "10283           3  Other  \n",
       "10284          88     ES  \n",
       "\n",
       "[10285 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
